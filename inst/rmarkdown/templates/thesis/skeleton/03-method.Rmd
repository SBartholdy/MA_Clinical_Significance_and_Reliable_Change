<!-- Required to number equations in HTML files -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

# Method {#method}

The present study constitutes an investigation of classification outcomes from different methods in simulated scenarios of a psychiatric trial with depressive patients.

<!------------------------------------------------------------------------------------------------------------->
## Study Design

The methodology follows a repeated-measures design with simulated patient data. Data were generated on the basis of various empirical data sets, ensuring the validity of findings. Simulation studies are characterized by relying on data that is generated and sampled pseudo-randomly on the basis of known distributions of the respective variables of interest. They can be used to empirically investigate the performance of statistical methods under specific conditions and allow to draw conclusions about them independently of context-specific influences that would otherwise be present in studies with real-world data [@Morris.2019].

<!------------------------------------------------------------------------------------------------------------->
## Data Simulation Procedure

All following analyses are based on mathematically simulated data sets that were generated for a previous study by @Schuster.2020. A detailed description of the simulation process can be found in the supplementary material of their article online ^[\url{https://doi.org/10.1016/j.invent.2020.100313}]. Estimated parameters and the data-generation process will be described in the following sections.
\par
Data were simulated for two essential scenarios, questionnaire and EMA, on the basis of empirical trials that were conducted with clinical samples of patients with diagnosed depression. As described in sections 2 and 3 of the appendix of the original article, the dependence structure between subsequent assessments was simulated using copulas (i.e. a Frank copula for control conditions and a Clayton copula for treatment conditions). While @Schuster.2020 generated and analyzed both \enquote{actual trial data} (scenario 2), which were informed by the EVIDENT trial [@Klein.2016], and realistic, synthetic data without a specific basis (scenarios 1 and 3), only the latter category was used in this thesis. The difference between them is that the so-called \enquote{actual trial data} scenario has differing pairwise correlations between subsequent assessments ($r_{tt}$ between .46 and .69), while the dependence structure of the other scenarios was set constantly as the average empirically found inter-correlations between assessments (i.e. $r_{tt}$ = .4 between subsequent EMA assessments and $r_{tt}$ = .7 between subsequent questionnaire assessments). As a special form, one simulation also included varying parameters accounting for potential systematic bias, such as a learning effect in EMA data (e.g., participant reactivity to repeated measurements.
\par
All simulated scenarios were based on data sets implementing the Patient Health Questionnaire-9 [PHQ-9, @Kroenke.2001], which is commonly used to evaluate changes in the degree of self-reported depressive symptoms. In this short scale, all 9 items are scored on a 4-point Likert scale (0-3), resulting in a total score between 0 and 27, with higher scores indicating more severe depressive mood. In practice, the PHQ-9 is being used in both assessment modalities, i.e. for questionnaire assessments and EMA.

<!------------------------------------------------------------------------------------------------------------->
### Simulated Scenarios

To give an overview, the characteristics of all investigated trial scenarios are summarized in Table \@ref(tab:data-structure). The simulation process leading to this data is described in Appendix \@ref(pre-pro).
\newline
\par
\textbf{Questionnaire Scenarios} include treatment conditions within intense 30-fold assessment intervals  (PP\textsubscript{30.30}), intense 5-fold random-window assessment intervals (PP\textsubscript{5.5-Window}), and single pre-post assessments (PP\textsubscript{1.1}), as well as no-treatment (control) conditions within intense 5-fold assessment intervals (PP\textsubscript{5.5}) and single pre-post assessments (PP\textsubscript{1.1}).
\par
\textbf{EMA Scenarios} include treatment conditions within intense 30-fold assessment intervals (EMA\textsubscript{30.30}), intense 5-fold random-window assessment intervals (EMA\textsubscript{5.5-Window}), and intense 5-fold random-day assessment intervals (EMA\textsubscript{5.5-Days}), as well as no-treatment (control) conditions within intense 5-fold assessment intervals (EMA\textsubscript{5.5}) and single pre-post assessments (EMA\textsubscript{1.1}).
\par

\begin{table}[thb]
\vspace*{1.5em}
\begin{threeparttable}
  \caption{\textit{Final Data Structure of the Simulated Scenarios, Including Standard-Questionnaire and EMA Scenarios With Three Different Sampling Frequencies Each Under Treatment Conditions, and Standard-Questionnaire and EMA Scenarios With Two Different Sampling Frequencies Each Under No-Treatment (Control) Conditions}}
  \label{tab:data-structure}
  \begin{tabular}{@{}ccccccc@{}}
  \toprule
  Condition & Scenario & $N$ & $d$ & Frequency & $r_{tt}$ & $\alpha$\\
  \midrule
  Treat & Standard Questionnaire & 8180 & 0.89 & 30-30       & 0.65 & 0.98\\
        &                        &      &     & 5-5 Window  & 0.66 & \textbf{0.87}\\
        &                        &      &     & 1-1         & 0.10 & 0.17\\
  \midrule
        & EMA & 8040 & 0.88 & 30-30      & 0.31 & 0.93\\
        &     &       &     & 5-5 Window & 0.31 & \textbf{0.62}\\
        &     &       &     & 5-5 Days   & 0.30 & 0.70\\
  \midrule
  No-Treat & Standard Questionnaire & 99810 & 0.00 & 5-5 & 0.66 & \textbf{0.83}\\
           &                        &       &      & 1-1 & 0.36 & 0.53\\
  \midrule
            & EMA & 99964 & 0.00  & 5-5  & 0.33 & \textbf{0.51}\\
            &     &       &       & 1-1  & 0.17 & 0.29\\
  \bottomrule
  \end{tabular}
  \begin{tablenotes}[para]
  \normalsize{\textit{Note.} Treat = treatment condition, No-Treat = no-treatment (control) condition, $d$ = effect size Cohen´s \textit{d} for the mean difference between the first pre- and the first post-assessment, $r_{tt}$ = average correlation between subsequent assessments (i.e. test-retest reliability), $\alpha$ = internal consistency Cronbach´s $\alpha$ between assessments, highlighting in bold font indicates which $\alpha$ estimate was implemented in Reliable Change Indices for each scenario respectively}
  \end{tablenotes}
\end{threeparttable}
\end{table}

Treatment-condition data sets for both diagnostic methods showed an overall effect size of Cohen´s _d_ between 0.88 (EMA) and 0.89 (standard questionnaire) for the symptom change from pre- to post-treatment assessments. Their overall treatment effect would therefore be considered large [@Cohen.2013], while lying within the range of real empiric effect sizes reported in research on psychiatric outcomes. No-treatment scenarios with _d_ = 0, on the other hand, were used in separate analyses to investigate how precise the included clinical significance methods recognized cases without meaningful changes (i.e. specificity), and in turn, how many cases were falsely classified as clinically meaningful changes (i.e. false positives).
\par
The correlation matrices of pre- and post-treatment assessments are given in Appendix \@ref(app-corrmats). The pairwise correlation coefficients between subsequent assessments, $r_{tt}$, were roughly equal both within and between pre- and post-treatment intervals for all included scenarios (pooled estimates of $r_{tt}$ are given in Table \@ref(tab:data-structure)). In detail, in treatment scenarios, the average correlation between subsequent assessments was $r_{tt}$ = .64-.65 in PP\textsubscript{30.30}, $r_{tt}$ = .65-.66 in PP\textsubscript{5.5-Window}, $r_{tt}$ = .10 in PP\textsubscript{1.1}, $r_{tt}$ = .31 in EMA\textsubscript{30.30}, $r_{tt}$ = .31 in EMA\textsubscript{5.5-Window}, and $r_{tt}$ = .29-.30 in EMA\textsubscript{5.5-Days}; and in no-treatment scenarios: $r_{tt}$ = .66-.67 in PP\textsubscript{5.5}, $r_{tt}$ = .36 in PP\textsubscript{1.1}, $r_{tt}$ = .33 in EMA\textsubscript{5.5}, and $r_{tt}$ = .17 in EMA\textsubscript{1.1}.
\par
As indicated in Table \@ref(tab:data-structure), the internal consistency Cronbach´s $\alpha$, was implemented to calculate some of the clinical significance methods (see Chapter \@ref(def-rci-ind)). It varied strongly between different assessment frequencies, which is expected, as $\alpha$ typically increases with the number of assessments. To control its differential effects on the classification accuracy of methods in these scenarios, $\alpha$ was taken from the 5-fold random-window scenario for use in calculations within each standard-questionnaire and EMA modality, e.g., $\alpha$ = .87 in PP\textsubscript{5.5-Window} for all three treatment-condition questionnaire scenarios and $\alpha$ = .62 in EMA\textsubscript{5.5-Window} for all three treatment-condition EMA scenarios.
\par
For a comparison to previous studies using the PHQ-9, for instance, @Titov.2011 reported a roughly similar internal consistency of $\alpha$ = .74 (before treatment) and $\alpha$ = .81 (after treatment), while other studies reported higher empirical estimates of $\alpha$, e.g., $\alpha$ = .87 in a study by @Hepner.2009 [see also @Adewuya.2006; @Kroenke.2001; @Kroenke.2010; @Lamers.2008].

<!------------------------------------------------------------------------------------------------------------->
## Clinical Interpretation of PHQ-9 Scores {#phq-int}

Within the PHQ-9 [@Kroenke.2001], depressive mood is evaluated as a sum score of its 9 items. The items of the PHQ-9 correspond to the diagnostic criteria of major depressive disorder in the DSM-IV [@AmericanPsychiatricAssociation.1995]. The severity of depressive symptoms is operationalized by the items retrospectively asking for the patient´s self-report on the frequency of experienced symptoms over the past 2 weeks. Each item scores on a Likert scale between 0 and 3, where 0 corresponds to \textit{\enquote{Not at all}}, 1 to \textit{\enquote{Several days}}, 2 to \textit{\enquote{More than half the days}}, and 3 to \textit{\enquote{Nearly every day}}. The total score of these subjective ratings therefore represents the severity of depressive mood based on the number of experienced symptoms and the frequency with which they were perceived over a period of 2 weeks.
\newline
\par

\begin{table}[bht]
\vspace*{1.5em}
\begin{threeparttable}
  \caption{\textit{Clinical Interpretation of Depressive Symptom Levels on the PHQ-9 Scale}}
  \label{tab:phq-int}
  \begin{tabular}{@{}ccc@{}}
  \toprule
  PHQ-9 Score & Classification & Depression Severity\\ 
  \midrule
  0--4 & 0 & Minimal or none\\
  5--9 & 1 & Mild\\
  10--14 & 2 & Moderate\\
  15--19 & 3 & Moderately severe\\
  20--27 & 4 & Severe\\
  \bottomrule
  \end{tabular}
  \end{threeparttable}
\end{table}

It is important to note that, although the items are originally formulated retrospectively, they are also commonly adapted to a daily EMA strategy by instructing participants to rate the specified symptoms on their intensity on the present day, instead of on their frequency over the past 2 weeks. Because of the intended daily-assessment structure underlying the simulated data sets, precisely this item variation of the PHQ-9 is assumed for the present study.
\par
The clinical interpretation categories of PHQ-9 Total scores are displayed in Table \@ref(tab:phq-int) [see @Karin.2018b; @Kroenke.2001]. The documentation of the PHQ-9 explicitly discourages diagnosing depressive disorders solely on the basis of the questionnaire. The interpretation categories given in Table \@ref(tab:phq-int) therefore do not exactly correspond to diagnostic levels of depression (with regards to classification systems, such as ICD-10 or DSM-5), but to scale-specific recommendations for interpretation.

<!------------------------------------------------------------------------------------------------------------->
## Classification Methods for Clinically Significant Change {#class-methods}

The following classification methods will be evaluated regarding their accuracy and agreement with each other:

+ the Percentage Change Method (PC),
+ the Reliable Change Index (RCI);
  + Reliable Change Index by Jacobson \& Truax (RCI\textsubscript{JT});
  + Repeated-Assessment Individualized Reliable Change Index with individual pre-treatment standard deviation (RCI\textsubscript{ind,pre-SD}).


\par \noindent
Their respective criteria for clinically significant change are listed in Table \@ref(tab:csi-int).

\begin{table}[h]
\vspace*{1.5em}
\begin{threeparttable}
  \caption{\textit{Clinically Significant Change Interpretation of PHQ-9 Scores, According to Percentage Change and Reliable Change Criteria}}
  \label{tab:csi-int}
  \small
  \begin{tabular}{@{}lcccc@{}}
  \toprule
  \multicolumn{1}{c}{Method} & PHQ-9 (Post) & Index Value & Classification & Interpretation \\
  \midrule
  \multirow{3}{*}{CSI\textsubscript{PC}} & $\leq$ 9 & PC $\geq$ 50 & -1 & Significant Improvement \\
 & > 9 & -50 < PC < 50 & 0 & No Significant Change \\
 & > 9 & PC $\leq$ -50 & 1 & Significant Deterioration \\
 \midrule
 \multirow{3}{*}{CSI\textsubscript{RCI}} & $\leq$ 9 & RCI < -1.96 & -1 & Significant Improvement \\
 & > 9 & -1.96 $\leq$ RCI $\leq$ 1.96 & 0 & No Significant Change \\
 & > 9 & RCI > 1.96 & 1 & Significant Deterioration \\
 \bottomrule
 \end{tabular}
\end{threeparttable}
\end{table}

<!------------------------------------------------------------------------------------------------------------->
### Percentage Change

The Percentage Change method (\textit{PC}), also known as Percentage Improvement method (\textit{PI}), describes longitudinal changes in test scores proportionally on an individual level. It results in an index that describes a subject´s post-treatment score as a proportion of his or her pre-treatment score. A positive result indicates that the post-treatment score is smaller than the pre-treatment score (i.e. improvement), while a negative result indicates a post-treatment score higher than the pre-treatment score (i.e. deterioration). The formula to calculate a PC index is given in Equation \@ref(eq:pc). Note that it can be applied equally as simple to single assessments as to average scores calculated from assessment intervals.

\begin{equation}
PC = \Bigl(1 - \frac{\overline{x_{2}}} {\overline{x_{1}}}\Bigr) \cdot 100 (\#eq:pc)
\end{equation}

> _Note._ $\overline{x_{2}}$ = mean of subject´s posttest scores, $\overline{x_{1}}$ = mean of subject´s pretest scores

\par \noindent
When applied on a common scoring system for a psychological construct, i.e. including only non-negative scores, the resulting index can assume values smaller than or equal to 100. This is a consequence of the fact that a person can not reduce his or her scores by more than 100%, as the lower bound of the scale itself is non-negative (most typically 0). But depending on the specific scale, it may well be possible that a subject can increase scores from pre- to post-treatment by more than 100%, indicated by a post-treatment score greater than two times the size of the pre-treatment score. Hence, the negative limit of the index (i.e. the most extreme expression of deterioration) is not defined a priori, but rather scale- and data-specific, as it is determined by the maximum of the empirical distribution of pre-treatment scores in relation to the highest achievable score on the scale.
\par
Percentage Change (Percentage Improvement) rates are commonly reported in psycho-pharmacological studies, mostly involving cutoff criteria of 25 or 50% [@Hiller.2012]. Furthermore, particularly for clinical trials on depressive disorders, a large body of research generally recommends using a criterion of $\geq$ 50% improvement to indicate significant treatment response [e.g., see @Bandelow.2006; @Frank.1991; @Hiller.2012; @Lecrubier.2002; @McMillan.2010; @Nierenberg.2001; @Rush.2006].
\par
Following the Clinical Significance method with a two-fold criterion, consisting of (1) proportional change significance in terms of Percentage Change and (2) clinical significance on a scale-specific cutoff score, subjects in the present study are evaluated according to the criteria given in Table \@ref(tab:csi-int). The listed criteria were adopted from the original validation study of the PHQ-9, which defined clinically significant improvement as (1) percentage improvement of PC $\geq$ 50%, combined with (2) a post-treatment score $\leq$ 9 [@McMillan.2010].

<!------------------------------------------------------------------------------------------------------------->
### Reliable Change Index

The Reliable Change Index (\textit{RCI}) was first introduced by @Jacobson.1984 and @Jacobson.1991. It is defined as a	standardized difference score that determines whether a score change is statistically significant, i.e. substantially exceeds the error variance of the assessment method. Hence, it determines if the observed score difference can be attributed to treatment effects rather than to naturally occurring variance in the sample.

<!------------------------------------------------------------------------------------------------------------->
#### Reliable Change [@Jacobson.1984; @Jacobson.1991]

Contemplating the sole reliance on statistical significance of tests, @Jacobson.1991 criticized widespread research approaches for the following problems: (1) comparisons on a group level ignore intra-individual variability and change, and (2) statistically significant group differences are therefore not synonymous with clinical relevance. To address these issues, the authors formulated a two-fold approach to evaluating clinically significant change, consisting of both statistical reliability (i.e. the RC index) and clinical significance in terms of symptom severity scores [@Jacobson.1984].
\par
The RC Index is a standardized measure of the raw score difference between two assessments. It quantifies the extent by which the score difference exceeds the error variance of the assessment method. A significant RCI therefore indicates that the observed change exceeds the measurement error by an extent upon which it can be confidently assumed that it is not caused by error variance, but rather by other factors, such as an applied clinical treatment. The conventionally applied significance cutoff is $|RCI|>1.96$, derived from the z score for 95% confidence, i.e. a two-sided $\alpha$ probability <.05. An $RCI > 1.96$ indicates statistically reliable deterioration, an $RCI < -1.96$ indicates reliable improvement, and $-1.96 \geq RCI \leq 1.96$ indicates no reliable change.

\begin{equation}
RCI = \frac{x_{2} - x_{1}}  {s_{diff}} (\#eq:rci-jt)
\end{equation}

\begin{equation}
s_{diff} = \sqrt{2 \cdot (SE)^2} (\#eq:rci-jt-sdiff)
\end{equation}

\begin{equation}
SE = s_{1} \cdot \sqrt{1 - r_{xx \text{´}}} (\#eq:rci-jt-se)
\end{equation}

> _Note._ $x_{2}$ = subject´s posttest score, $x_{1}$ = subject´s pretest score, $s_{diff}$ = standard error of difference between test scores, $SE$ = standard error of measurement, $s_{1}$ = standard deviation of test scores at pretest, $r_{xx \text{´}}$ = reliability of the measure

\par \noindent
For instance, a significant RC index of $\pm 2$ would show that the score difference was equal to two standard deviations, weighted by the reliability of the method. Furthermore, @Jacobson.1984 and @Jacobson.1991 offer an additional formula for the calculation of a significance cutoff given in raw scores:

\begin{equation}
\textit{significance cutoff} = 1.96 \cdot s_{diff} = 1.96 \cdot \sqrt{2 \cdot (s_{1} \cdot \sqrt{1 - r_{xx \text{´}}})^2} (\#eq:rci-jt-cut)
\end{equation}

> _Note._ $\textit{significance cutoff}$ = (absolute) cutoff score for reliable change (95%-criterion)

\par \noindent
This formula defines the raw score that an individual would have to gain or lose in the given test to be recognized as reliably changed. It is also based on the whole sample´s characteristics. The estimates should be calculated using the standard deviation of either a control group, a normal population, or an experimental group at the baseline assessment (for an adaptation using within-subjects variability, see the proposed RCI\textsubscript{ind,pre-SD} in the following section). It also includes the test-retest reliability, which is oftentimes available in the test documentation or in published validation studies.
\par
Following from the assumption of normally distributed change scores, an individual RCI score could also be interpreted in the sense of percentage ranks, i.e.: Assuming normality, it is expected that $X \%$ of participants getting the same treatment under the same conditions would show an improvement or deterioration of at most the same extent.
\par
Regarding the recommended use cases of the RCI\textsubscript{JT}, there is a general consensus between the original authors and following studies. For instance, @HintonBayre.2000 argues that the RCI\textsubscript{JT} is appropriate when only pretest data and the test reliability are available and a true change in the construct, independently of treatment effects, is not expected. If normative retest data are available, he argues for the inclusion of the post-treatment variance. The absence of true change in the construct is a critical precondition, because in many assessment contexts there are practice effects, regression toward the mean or divergence from the mean, and natural fluctuations in the construct. If these changes are expected independently of an intervention, they need to be taken into account as error variance [@Busch.2015]. When true changes are expected additionally to the effects of experimental interventions, e.g., in the form of practice effects or spontaneous remission, especially regression-based calculation approaches can be used to correct the obtained scores (e.g., hierarchical linear models).

<!------------------------------------------------------------------------------------------------------------->
#### Defining an Individualized Reliable Change Index {#def-rci-ind}

The Individualized Reliable Change Index, \textit{RCI\textsubscript{ind}}, is proposed as an adaptation of the originally defined RCI to repeated-measurement data including more than two timepoints, such as data from EMA procedures. RCI\textsubscript{ind} scores are standardized estimates for the reliable change of a single person, as they are based on each individual´s variance, instead of relying on group-level variance estimates.
\par
The proposed individualized formula, the RCI\textsubscript{ind,pre-SD}, is adapted to include more than two single assessments in its numerator: The originally included score difference between two single scores is replaced by the average difference between a pre-treatment and a post-treatment assessment interval. Through averaging, the number of assessments in each interval can vary between subjects and missing data could be imputed or, after careful consideration, even ignored. It also includes a subject-level standard error, $SE_{D, pre}$. This standard error is calculated using the reliability of the assessment method and the standard deviation of each individual´s scores throughout the pre-treatment interval. In this way, the individual´s pre-post difference is relativized by their own measurement error, which includes both within-subject fluctuation of scores and the reliability (i.e. consistency) of the method. Similar to the RCI\textsubscript{JT}, an individual cutoff score for significant change can also be calculated easily.

\begin{equation}
RCI_{\textit{ind,pre-SD}} = \frac{\overline{x_{2}} - \overline{x_{1}}}  {SE_{D,pre}} (\#eq:rci-ind-presd)
\end{equation}

\begin{equation}
SE_{D,pre} = \sqrt{2 \cdot (s_{x} \cdot (1 - r_{xy})^2)} (\#eq:rci-ind-presd-se)
\end{equation}

\begin{equation}
\textit{significance cutoff} = 1.96 \cdot SE_{D,pre} = 1.96 \cdot \sqrt{2 \cdot (s_{x} \cdot (1 - r_{xy})^2)} (\#eq:rci-ind-presd-cut)
\end{equation}

> _Note._ $\overline{x_{2}}$ = mean of subject´s posttest scores, $\overline{x_{1}}$ = mean of subject´s pretest scores, $SE_{D,pre}$ = standard error of difference between the test scores in the individual´s pre interval, $s_{x}$ = individual standard deviation of pretest time points, $r_{xy}$ = reliability (internal consistency Cronbach´s $\alpha$) of the measure, $\textit{significance cutoff}$ = (absolute) cutoff score for reliable change (95%-criterion)

\par \noindent
Significance cutoff scores for the individualized RCI give the absolute scale points that an individual would have to gain or lose on the respective scale to be classified as reliably changed. However, contrary to the RCI\textsubscript{JT}, the cutoff score in Equation \@ref(eq:rci-ind-presd-se) is calculated individually on each subject. Thus, it is not assumed that there exists a universal cutoff score to decide clinically significant change for all participants in a sample. Rather, each subject would need to pass a personally defined range of points in either direction to be considered reliably deteriorated or improved.
\par
The RCI\textsubscript{ind,pre-SD} formula is a simple adaptation of the original RC approach by @Jacobson.1984 and @Jacobson.1991, but, resulting from a few changes, the proposed estimate is interpreted differently, specifically because (1) it is calculated over assessment intervals rather than single assessments and (2) it is no longer based on a group-level estimate of variance in a single assessment, but on the individual´s score fluctuation over whole intervals. The inclusion of a subject's individual standard deviation(s), rather than group- or population-level estimates of variability, neither understates the individual error term nor inflates it through the influence of test scores of subjects other than the individual of interest. Nonetheless, the variability of a sample or population's responses to the given test is still considered informative for the individual, and is nevertheless a part of the test's reliability, i.e. included in the measurement error.
\par
For the estimate of reliability in the standard error, similar to the RCI\textsubscript{JT}, it is recommended to use the internal consistency Cronbach´s $\alpha$ instead of the test-retest reliability $r_{tt}$. While $r_{tt}$ is used in some common RCI approaches, in contexts where unstable psychological constructs are measured over time, the internal consistency Cronbach's $\alpha$ is more appropriate for the following reasons: As @Cronbach.1947 described in his review of reliability coefficients, the test-retest reliability can be an accurate estimate of measurement accuracy only if the measured construct is expected to be stable over time. By definition, measurement variance in a single test score can only be distinguished from real construct variance over time if the construct does not vary between assessments in reality [@Maassen.2009; @Wyrwich.2004]. Since constructs examined in clinical research and practice are not expected to be stable, but are examined specifically for changes over time, the test-retest reliability is not considered suitable for calculating a reliable index of change. This issue has been addressed in early studies, but is still often not taken into account in clinical research. For instance, @Martinovich.1996 and @Tingey.1996 similarly recommend using the internal consistency instead of the retest reliability.
\par
A person´s average difference in test scores between the two assessment intervals, however large or small it may be, is relativized not only by the reliability (i.e. consistency) of the measurement instrument, but also by the person's own variability in responses to the instrument. Consequently, a person with a relatively large mean difference in a measured construct, but also with much variability in individual test scores over time, will be assigned a smaller RCI than another person with the same mean difference and less variability in test scores. This is because there is a reasonably higher confidence in the accuracy of the resulting difference in test scores for the latter person than for the former.
\par
Following the Clinical Significance method with a two-fold criterion, consisting of (1) statistical significance on a Reliable Change Index and (2) clinical significance on a scale-specific cutoff score, subjects in the present study are evaluated according to the criteria given in Table \@ref(tab:csi-int). It should be noted that the originally introduced 3-class interpretation of RCIs can also be extended to better specify different levels of improvement, as suggested by @Lambert.2009: Patients could be classified as _recovered_ (if the passed both criteria), _improved_ (if they passed only the RCI criterion in the positive direction), _unchanged_ (if they did not pass the RCI criterion), or _deteriorated_ (if they passed the RCI criterion in the negative direction).

<!------------------------------------------------------------------------------------------------------------->
## Analyses of Sensitivity and Specificity

After defining the statistical terms of interest in Chapter \@ref(theory-pss), their precise implementations regarding the research question and data ought to be clarified shortly.
\par
In the present study, positive cases are equivalent to true cases of meaningful change, and therefore include both _true_ improvement and deterioration. Negative cases are equivalent to true cases of no meaningful change. In order to apply the definition of sensitivity (see Equation \@ref(eq:sensitivity)) to the three classes of change interpretation, a class-weighted average sensitivity can be calculated in the following way:

\begin{equation}
\begin{aligned}
Sensitivity_{\textit{cwa}} = \frac{1}{n} \sum_{k=1}^{c} tp^{(k)} = \frac{tp^{(det)}} {tp^{(det)} + fn^{(det)}} + \frac{tp^{(\textit{nc})}} {tp^{(\textit{nc})} + fn^{(\textit{nc})}} + \frac{tp^{(imp)}} {tp^{(imp)} + fn^{(imp)}} (\#eq:sensitivity-cwa)
\end{aligned}
\end{equation}

\par \noindent
Equally, the class-weighted average specificity is calculated in the following way:

\begin{equation}
\begin{aligned}
Specificity_{\textit{cwa}} = \frac{1}{n} \sum_{k=1}^{c} tn^{(k)} = \frac{tn^{(det)}} {tn^{(det)} + fp^{(det)}} + \frac{tn^{(\textit{nc})}} {tn^{(\textit{nc})} + fp^{(\textit{nc})}} + \frac{tn^{(imp)}} {tn^{(imp)} + fp^{(imp)}} (\#eq:specificity-cwa)
\end{aligned}
\end{equation}

> _Note._ $c$ = number of classes $k$ (i.e. 3: deteriorated; not changed; improved); $n$ = total number of cases; $tp^{k}$ = proportion of true positive cases in class k; $fn^{k}$ = proportion of false negative cases in class k; $tn^{k}$ = proportion of true negative cases in class k; $fp^{k}$ = proportion of false positive cases in class k

<!------------------------------------------------------------------------------------------------------------->
## False-Positive Rate and Specificity in a Control Group

False-positive rates and the specificity of clinical change methods were investigated in questionnaire and EMA scenarios with overall within-subjects effect sizes of Cohen´s _d_ $\approx$ 0, representing the scores of a control group in a clinical trial. The characteristics of these data sets are summarized in Table \@ref(tab:data-structure). Although some participants in these simulated scenarios showed a substantial symptom improvement or deterioration, the overall pre-post symptom changes were closely distributed around 0, with the vast majority of cases showing no meaningful changes in absolute scores. The main advantage of using zero-effect data sets for this analysis is that the absence of a general treatment effect, along with equally distributed random positive and negative effects, enables the a-priori assumption that proportions of cases identified as changed should be minimal in the most specific calculation methods. The respective cases would only constitute false-positive classifications (i.e. both classifications of improvement and of deterioration), as the number of truly changed participants would be _P_ = _TP_ + _FN_ = 0, implying that cases of true change could neither be detected (i.e. _TP_ = 0) nor overlooked (i.e. _FN_ = 0) in these scenarios. Following from their definitions, classification sensitivity (see Equation \@ref(eq:sensitivity)) could not be calculated under these conditions, while the classification specificity (see Equation \@ref(eq:specificity)) could be appropriately estimated with regard to the known _ground truth_ of the whole sample consisting of only negative (i.e. non-changed) cases.
\newline
\par \noindent
The _false-positive rate (FPR)_ is given by:
\begin{equation}
FPR = \frac{FP}{N} = \frac{FP}{FP + TN} (\#eq:fpr)
\end{equation}

\par \noindent
Hence, classification methods can be compared regarding their false-positive rates and their specificity (i.e. probability of true-positive classifications) on the basis of this data.
